<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/images/icon.png"><link rel="icon" href="/images/icon.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="charlesix59"><meta name="keywords" content=""><meta name="description" content="hadoop知识点整理第一章 大数据的概念大数据是指无法用现有的软件工具提取、存储、搜索、共享、分析和处理的海量的复杂的数据图集。 特征4个V：  Volume：数据体量巨大  Variety：数据种类繁多  Value：数据价值密度低  Velocity：处理速度快   hadoop生态圈大数据工具主要包括：Hadoop、Hbase、ZooKeeper、Hive、Mahout、Sqoop、Sto"><meta property="og:type" content="article"><meta property="og:title" content="Hadoop 知识整理"><meta property="og:url" content="2023/06/04/subject/hadoop/index.html"><meta property="og:site_name" content="茶理的私人博客"><meta property="og:description" content="hadoop知识点整理第一章 大数据的概念大数据是指无法用现有的软件工具提取、存储、搜索、共享、分析和处理的海量的复杂的数据图集。 特征4个V：  Volume：数据体量巨大  Variety：数据种类繁多  Value：数据价值密度低  Velocity：处理速度快   hadoop生态圈大数据工具主要包括：Hadoop、Hbase、ZooKeeper、Hive、Mahout、Sqoop、Sto"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2023-06-04T07:21:43.390Z"><meta property="article:modified_time" content="2023-06-16T01:20:03.351Z"><meta property="article:author" content="charlesix59"><meta property="article:tag" content="Java"><meta property="article:tag" content="hadoop"><meta name="twitter:card" content="summary_large_image"><meta name="referrer" content="no-referrer-when-downgrade"><title>Hadoop 知识整理 - 茶理的私人博客</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="//unpkg.com/heti/umd/heti.min.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><script type="text/javascript" src="/js/love.js"></script><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"https:/charlesix59.github.io",root:"/",version:"1.9.2",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 6.2.0"></head><body><header><script type="text/javascript" color="0,160,230" opacity="0.7" zindex="-2" count="200" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>茶理的博客</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/default.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="Hadoop 知识整理"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2023-06-04 15:21" pubdate>2023年6月4日 下午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 6.6k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 56 分钟</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">Hadoop 知识整理</h1><div class="markdown-body"><h1 id="hadoop知识点整理"><a href="#hadoop知识点整理" class="headerlink" title="hadoop知识点整理"></a>hadoop知识点整理</h1><h2 id="第一章-大数据的概念"><a href="#第一章-大数据的概念" class="headerlink" title="第一章 大数据的概念"></a>第一章 大数据的概念</h2><p>大数据是指无法用现有的软件工具提取、存储、搜索、共享、分析和处理的海量的复杂的数据图集。</p><h3 id="特征"><a href="#特征" class="headerlink" title="特征"></a>特征</h3><p><strong>4个V</strong>：</p><ul><li><p>Volume：数据体量巨大</p></li><li><p>Variety：数据种类繁多</p></li><li><p>Value：数据价值密度低</p></li><li><p>Velocity：处理速度快</p></li></ul><h3 id="hadoop生态圈"><a href="#hadoop生态圈" class="headerlink" title="hadoop生态圈"></a>hadoop生态圈</h3><p>大数据工具主要包括：Hadoop、Hbase、ZooKeeper、Hive、Mahout、Sqoop、Storm等</p><h4 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h4><p><strong>Doug Cutting</strong>开发，受到<strong>Map&#x2F;Reduce</strong>启发，核心是<strong>MapReduce编程模型和HDFS分布式文件系统</strong>。</p><p>采用分而治之的思想，Map用来切分大的数据，Reduce用来合并Map计算的结果。</p><p>HDFS 分布式文件系统，为海量数据提供存储服务，将大文件拆分为块，多节点存放，具有高吞吐量、高容错性的特点。</p><h4 id="HBASE"><a href="#HBASE" class="headerlink" title="HBASE"></a>HBASE</h4><p>HBASE是Apache开源的KV型数据库，是建立在HDFS之上，提供高可靠性、高性能、列存储、可伸缩、实时读写的数据库系统。</p><p>仅支持单行事务。</p><p>主要用来存储非结构化和半结构化的松散数据。</p><h4 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h4><p>Apache Hive数据仓库软件提供对存储在分布式中的大型数据集的查询和管理，它本事是建立在Hadoop之上的</p><h4 id="Storm"><a href="#Storm" class="headerlink" title="Storm"></a>Storm</h4><p>Apache Storm是一个免费、开源的分布式实时计算机系统，简化了数据流的可靠处理。</p><h4 id="ZooKeeper"><a href="#ZooKeeper" class="headerlink" title="ZooKeeper"></a>ZooKeeper</h4><p>zooKeeper是一个高性能、分布式的开源分布式应用协调服务，他是storm、hbase的重要组件，它是一个为分布式应用提供一致性服务的软件。</p><p>服务端跑在JAVA上</p><p>ZooKeeper有两个角色，一个是leader，负责写服务和数据同步，剩下的是follower，提供读服务。</p><p><strong>特点</strong>：</p><ul><li><p>顺序一致性：按照客户端发送请求的顺序更新数据</p></li><li><p>原子性</p></li><li><p>单一性：无论客户端连接哪个server都看到同一个视图</p></li><li><p>可靠性：一旦数据更新成功将一直保持，直到新的更新</p></li><li><p>及时性：客户会在一个确定的时间内得到最新的数据</p></li></ul><p><strong>运用场景</strong>：</p><ul><li><p>数据发布订阅</p></li><li><p>名空间服务</p></li><li><p>分布式通知</p></li><li><p>分布式锁</p></li><li><p>集群管理</p></li></ul><h4 id="sqoop"><a href="#sqoop" class="headerlink" title="sqoop"></a>sqoop</h4><p>sqoop是Apache顶级项目，允许用户将数据从关系型数据库中抽取数据到Hadoop中</p><h4 id="mahout"><a href="#mahout" class="headerlink" title="mahout"></a>mahout</h4><p>mahout是一个强大的数据挖掘工具，是一个分布式机器学习算法的集合，包括分布式协同过滤的实现、分类、聚类等</p><h3 id="Hadoop历史和版本"><a href="#Hadoop历史和版本" class="headerlink" title="Hadoop历史和版本"></a>Hadoop历史和版本</h3><p>历史：</p><ul><li><p>2011年12月，Apache基金会发布了Apache Hadoop 版本1.0</p></li><li><p>2013年8月，版本2.0.6可用</p></li><li><p>2017年12月发布Apache Hadoop3</p></li></ul><p>发行版：</p><p>Hadoop有许多变体：</p><ul><li><p>Cloudera Hadoop分布：是Coludera Enterprise的核心，包括Apache Hadoop、Apache Spark，Apache Kafka 以及十多个其他紧密继承的领先开源项目</p></li><li><p>Hortonworks Hadoop分布：是基于YARN的安全性强、企业就绪的开源版本</p></li><li><p>MapR Hadoop分布：是Hadoop的完成整企业级发行版</p></li><li><p>PivotalHD：是领先的基于标准的Hadoop该发行版，为Business Data Lake架构奠定了基础</p></li></ul><p>优势：</p><ul><li><p>高可靠性</p></li><li><p>高拓展性</p></li><li><p>高效性</p></li><li><p>高容错性</p></li></ul><h2 id="第二章-Hadoop-组成与结构"><a href="#第二章-Hadoop-组成与结构" class="headerlink" title="第二章 Hadoop 组成与结构"></a>第二章 Hadoop 组成与结构</h2><p>Hadoop1的三大核心模块：</p><ul><li><p>Common模块：支持其他模块的工具模块</p></li><li><p>HDFS模块：一个高可靠、高吞吐量的分布式文件系统</p></li><li><p>MapReduce模块：一个分布式的资源调度和离线并行计算系统</p></li></ul><p>Hadoop2的组成：</p><p>MapReduce模块仅作为分布式计算框架存在，资源调度功能交给YARN来调度处理</p><h3 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h3><p>一个分布式文件系统。</p><p>HDF的设计适合一次写入多次读出的场景且不支持文件修改。适合用来做数据分析，并不适合做网盘使用。</p><p>Master-Slave结构，Master是NameNode，Slave是DataNode</p><p>client职责如下：</p><ul><li><p>文件切分</p></li><li><p>与NameNode交互获取文件的位置信息</p></li><li><p>与DataNode交互读取或写入数据</p></li><li><p>提供一些明恋来管理HDFS，比如启动或者关闭HDFS</p></li><li><p>可以通过一些命令来访问HDFS</p></li></ul><p>NameNode职责如下：</p><ul><li><p>配置副本策略</p></li><li><p>处理client读写请求</p></li><li><p>管理block（数据块）映射信息，以元数据的形式存储在Fsimage镜像文件中</p></li><li><p>管理HDFS命名空间</p></li></ul><p>DataNode的职责：</p><ul><li><p>执行实际的数据块</p></li><li><p>执行数据块的读写操作</p></li></ul><p>SecondaryNameNode，第二名称节点，并非名称节点的热备，晋档NameNode重启或者热备NameNode激活时将宕机前所保留集群的快照发送给NameNode以恢复此前集群的状态。具体功能为：</p><ul><li><p>存辅NameNode，分担其工作量</p></li><li><p>定期合并Fsimage和Edits，并推送给NameNode</p></li><li><p>在紧急情况下可辅助恢复NameNode</p></li></ul><p>优点：</p><ul><li><p>高容错性</p></li><li><p>适合大数据处理</p></li><li><p>支持流式数据访问</p></li><li><p>可构建在廉价机器上</p></li></ul><p>缺点：</p><ul><li><p>不适合低延时数据访问</p></li><li><p>无法高效的对大量小文件进行存储</p></li><li><p>不支持并发写入文件和随机修改</p></li></ul><h3 id="YARN架构"><a href="#YARN架构" class="headerlink" title="YARN架构"></a>YARN架构</h3><p>MRv1的局限：</p><ul><li><p>扩展性差</p></li><li><p>可靠性差</p></li><li><p>资源利用率低</p></li><li><p>无法支持多种计算机框架</p></li></ul><p>YARN是一个弹性计算平台，他的目标已经不局限于支持MapReduce一种计算框架，而是朝着对多种框架的统一管理前进</p><p>优点：</p><ul><li><p>资源利用率高</p></li><li><p>运维成本低</p></li><li><p>数据共享</p></li></ul><p>对比：</p><table><thead><tr><th></th><th>V1</th><th>V2</th></tr></thead><tbody><tr><td>基本框架</td><td>JobTracker由资源管理和作业控制两部分组成</td><td>将JobTracker的两个功能拆分成两个独立的进程，资源管理进程负责整个集群的资源，而作业控制则是直接与应用程序相关的模块，每个进程只负责一个作业</td></tr><tr><td>编程模型与数据处理引擎</td><td></td><td>MRv2重用了v1中的编程模型与数据处理引擎</td></tr><tr><td>运行时环境</td><td>由JobTracker和TaskTracker两类服务组成，JT负责资源和任务的管理与调度，TT负责单个节点的资源管理和任务进行</td><td>将资源部管理与应用程序管理分开，分别又YARN和ApplicationMaster负责</td></tr></tbody></table><h4 id="YARN基本架构"><a href="#YARN基本架构" class="headerlink" title="YARN基本架构"></a>YARN基本架构</h4><p>总体上仍然是Master&#x2F;Slave架构</p><p>YARN的组成成分如下：</p><ul><li><p>ResourceManager：一个全局的资源管理器，负责整个系统的资源管理与分配。它由两个组件构成：</p><ul><li><p>调度器（Scheduler）：根据容量、队列等限制条件将资源分配给各个正在运行的应用程序</p></li><li><p>应用程序管理器（Application Manager ASM）：负责整个系统中所有应用程序</p></li></ul></li><li><p>ApplicationMaster（AM）的主要功能有：</p><ul><li><p>与RM调度器协商以获取资源（Container）</p></li><li><p>将得到的任务进一步分给内部任务</p></li><li><p>与NM通信以启动&#x2F;停止任务</p></li><li><p>监控所有任务运行状态</p></li></ul></li><li><p>NodeManager：是每个节点上资源和任务管理器</p></li><li><p>Container：是YARN山中的资源抽象，它封装了某个节点上的多维度资源</p></li></ul><h2 id="第三章-Hadoop运行模式与大数据技术框架"><a href="#第三章-Hadoop运行模式与大数据技术框架" class="headerlink" title="第三章 Hadoop运行模式与大数据技术框架"></a>第三章 Hadoop运行模式与大数据技术框架</h2><p>Hadoop的运行模式主要有四种：</p><ul><li><p>本地模式</p></li><li><p>伪分布式</p></li><li><p>全分布式</p></li><li><p>高可用模式</p></li></ul><h3 id="伪分布式模式"><a href="#伪分布式模式" class="headerlink" title="伪分布式模式"></a>伪分布式模式</h3><p>Hadoop可以运行在单个节点上，其中每一个Hadoop守护进程运行在单独的Java进程中，这个模式称之为伪分布式模式。Hadoop所有进程都运行在一台服务器以模拟全分布式模式，常用于学习阶段。</p><p>后台的五个进程为：</p><ul><li><p>NameNode</p></li><li><p>DataNode</p></li><li><p>SecondaryNameNode</p></li><li><p>ResourceManager</p></li><li><p>NodeManager</p></li></ul><h3 id="高可用模式"><a href="#高可用模式" class="headerlink" title="高可用模式"></a>高可用模式</h3><p>Hadoop是一种主从式架构，这样就会有<strong>单点故障</strong>的问题</p><h2 id="HDFS-1"><a href="#HDFS-1" class="headerlink" title="HDFS"></a>HDFS</h2><ul><li><p>数据块（block）</p><ul><li><p>HDFS默认的最基本的存储单位是128MB的数据块</p></li><li><p>128M为一块</p></li><li><p>一个文件如果小于一个数据块的大小，并不占用整个数据块的空间</p></li></ul></li><li><p>存放策略（3副本）</p><ul><li><p>第一个和client同node</p></li><li><p>第二个放在与第一个节点的不同机架中的随机的一个node</p></li><li><p>第三个放在与第一个节点不同的机架中与第二个不同的随机node中</p></li></ul></li><li><p>NameNode 和DataNode</p><ul><li><p>HDFS体系结构中有两类节点，一类是NameNode ( Master) ，又叫”元数据节点”;另一类是DataNode (Slave) ，又叫”数据 节点”。</p></li><li><p>元数据节点用来管理文件系统的命名空间，作用如下：</p><ul><li><p>其将所有的文件和文件夹的元数据保存在一个文件 系统树中</p></li><li><p>这些信息也会在硬盘上保存成以下文件:命名空间镜像(namespace image)及修改日志(edit log)</p></li><li><p>还保存了一个文件包括哪些数据块，分布在哪些数据节点上，然而这些信息并不存储在硬盘上，而是在系统启动的时候从数据节点收集而成的</p></li></ul></li><li><p>数据节点是文件系统中真正存储数据的地方，作用如下:</p><ul><li><p>客户端(clien)或者 元数据信息(namenode)可以向数据节点请求写入或者读出数据块</p></li><li><p>周期性的向元数据节点回报其存储的数据块信息</p></li></ul></li><li><p><code>hadoop.tmp.dir</code>，临时目录，其他临时目录的父目录，默认 <code>/tmp/hadoop-$&#123;user.name&#125;</code>，在<code>core-site.xml</code>中配置</p></li><li><p>元数据节点目录结构，在<code>hdfs-site.xml</code>中配置<code>dfs.name.dir</code>参数，以<code>,</code>分隔，默认在<code>&#123;hadoop.tmp.dir&#125;/dir/name</code></p></li></ul></li><li><p>数据节点目录结构</p><ul><li>在<code>hdfs-site.xml</code>中配置参数<code>dfs.data.dir</code>，以<code>,</code>分隔</li></ul></li><li><p>HDFS通信协议</p><ul><li>所有HDFS通信协议都是构建在TCP&#x2F;IP协议上的</li></ul></li><li><p>HDFS安全模式</p><ul><li>Namenode启动后会进入一种称为安全模式的特殊状态。处于安全模式的Namenode是不会进行数据块的复制的。Namenode从所有的DataNode接受心跳信号和块状态报告</li></ul></li></ul><p><strong>Name Node、DataNode 和Client</strong></p><ul><li><p>Namencodte 是分布式文件素统中的管理者， 主要负责管理 文件系统的命名空间、集群配置信息和存储块的复制等。NameNode 会将文件系统的Meta-data 存储在内存中，这些信息主要包括了文件信息，每个文件对应的文件块的信息和每个 文件块DataNode的信息等。</p></li><li><p>DataNode是文件存储的基本单元， 它将Block 存储在本地文件系统中，保存了Block 的meta-data,同时 周期性地将所有存在的Block信息发送给NameNode.</p></li><li><p>Client 就是需要获取分布式文件系统文件的应用程序。</p></li><li><p>Client读取文件信息</p></li></ul><h3 id="Hadoop-Shell命令"><a href="#Hadoop-Shell命令" class="headerlink" title="Hadoop Shell命令"></a>Hadoop Shell命令</h3><p>实际上是属性，命令为：<code>hadoop fs -xx</code></p><ul><li><p><code>cat</code>:</p></li><li><p><code>chgrp</code>: change group</p></li><li><p><code>chmod</code>:</p></li><li><p><code>chown</code></p></li><li><p><code>copyFromLocal</code></p></li><li><p><code>copyToLocal</code></p></li><li><p><code>cp</code>: copy</p></li><li><p><code>du</code>：显示目录中所有文件的大小</p></li><li><p><code>dus</code>：显示单个文件大小</p></li><li><p><code>expunge</code>：清空回收站</p></li><li><p><code>get</code>：复制到本地</p></li><li><p><code>getmerge</code>：将 source dir 中的文件链接成 local target dir</p></li><li><p>ls</p></li><li><p>lsr：递归ls</p></li><li><p>mkdir</p></li><li><p>movefromLocal</p></li><li><p>mv</p></li><li><p>put：本地到远程</p></li><li><p>rm</p></li><li><p>rmr：递归rm</p></li><li><p>setrep：改变副本数</p></li><li><p>stat：返回指定路径的统计信息</p></li><li><p>tail：将尾部1kb的字节输出到stdout</p></li><li><p>test：检测文件是否存在</p></li><li><p>text：将源文件输出为文本格式</p></li><li><p>touchz：新建一个0自己的文件</p></li></ul><p>Hadoop管理命令：</p><ul><li><p>distcp：分布式拷贝（集群之间）</p></li><li><p>fsck：检查整个文件系统的健康情况</p></li><li><p>jar：运行java文件</p></li><li><p>job：用于和MapReduce交互</p></li><li><p>balancer：运行集群平衡工具</p></li><li><p>dfsadmin：运行一个dfs admin客户端</p></li><li><p>namenode： 运行namenode</p></li></ul><h3 id="java接口"><a href="#java接口" class="headerlink" title="java接口"></a>java接口</h3><p>Hadoop中关于文件操作类基本都在<code>org.apache.hadoop.fs</code>包中</p><p>Hadoop类库中最终面向用户提供接口是<code>FileSystem</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// 获取FileSystem具体类</span><br><span class="hljs-keyword">static</span> FileSystem <span class="hljs-title function_">get</span><span class="hljs-params">(Configuration conf)</span>;<br><span class="hljs-comment">// 写文件</span><br><span class="hljs-keyword">public</span> FSDataOutputStream <span class="hljs-title function_">create</span><span class="hljs-params">(Path f)</span> <span class="hljs-keyword">throws</span> IOException;<br><span class="hljs-comment">//读文件</span><br><span class="hljs-comment">// 上传文件到HDFS</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">copyFileLocalFile</span><span class="hljs-params">(Path src,Path dist)</span>;<br><span class="hljs-comment">// 重命名文件</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">abstract</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">rename</span><span class="hljs-params">(Path src, Path dist)</span>;<br><span class="hljs-comment">// 删除文件&amp;目录</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">abstract</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">delete</span><span class="hljs-params">(Path f, <span class="hljs-type">boolean</span> recursive)</span> <span class="hljs-keyword">throws</span> IOException;<br><span class="hljs-comment">// 创建目录</span><br><span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">mkdirs</span><span class="hljs-params">(Path f)</span> <span class="hljs-keyword">throws</span> IOException;<br><span class="hljs-comment">// 遍历目录</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">abstract</span> FileStatus[] listStatus(Path f) <span class="hljs-keyword">throws</span> FileNotFoundException, IOException<br></code></pre></td></tr></table></figure><h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">map</span><span class="hljs-params">(Object Key,Text value,Context context)</span><br><span class="hljs-keyword">throws</span> IOExcetion, InterruptedException&#123;<br>    <br>&#125;<br></code></pre></td></tr></table></figure><h3 id="MapReduce工作原理"><a href="#MapReduce工作原理" class="headerlink" title="MapReduce工作原理"></a>MapReduce工作原理</h3><p>MapReduce框架的运作完全基于“键值对”，即数据的输入是一批“键值对” (key-value) ，生成的结果也是批“键值对”，只是有时候它们的类型不一样而已。Key和value的类由于需要支持被序列化 (Serealire) 操作，所以它们必须要实现<code>Writable</code> 接口，而且key的类还必须实现<code>WirtableComparable</code>接口，使得可以让框架对数据集的执行排序操作，MapRedtre运行机制，按照时间顺序包括:输入分片(input split)、map 阶段、combiner 阶段、shuffle阶段和reduce阶段。</p><p>在进行map计算之前，MapReduce会根据输入文件计算输入分片</p><h3 id="YARN运行流程"><a href="#YARN运行流程" class="headerlink" title="YARN运行流程"></a>YARN运行流程</h3><ol><li><p>JobClient 向YARY中提交应用程序，其中 包括ApplicationMaster 程序、启动ApplicationMaster的命令、用户程序、环境变量、作业信息、文件位置信息等</p></li><li><p>RecourseManager为该应用程序分配第一个 Container. 并与对应的 Node-Manager 通信（通过心跳方式），更求它在这个Container中启动应用程序的ApplicationMaster</p></li><li><p>ApplicationMaster首先向ReoourceManager注册，这样用 户可以直接通过ResourceManager查看应用程序的运行状态。然后它将为各个任务申请资源，并监控它的运行状，直到运行结束</p></li><li><p>ApplicationMaster 采用轮询的方式通过RPC协议向ResourceManager申请和领取资源</p></li><li><p>一旦ApplicationMaster申请到资源后，便与对应的NodeManager通信，要求它启动任务</p></li><li><p>NodeManager为任务设置好运行环境(包括环境变量、JAR包、二进制程序等)后，将任务启动命令写到一个脚本中， 并通过运行该脚本启动任务。</p></li><li><p>各个任务通过某个RPC协议向AplcationMaster汇报自己的状态和进度，以让ApplicationMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务。</p></li><li><p>应用程序运行完成后， ApplicationMaster向ResourceManager注销并关闭自己</p></li></ol><h3 id="作业关键过程详解"><a href="#作业关键过程详解" class="headerlink" title="作业关键过程详解"></a>作业关键过程详解</h3><p><strong>map</strong>：map任务最终是交给Map任务执行器</p><p><strong>Reduce</strong>：从所有map节点取到属于自己的map输出</p><p><strong>Partitioner</strong>：当Mapper处理好数据后，需要使用Partitioner（分区器）确定怎样合理地将Mapper输出分配到Reduce上</p><p><strong>Combiner</strong>：相当于一个本地的Reduce，主要是对Mapper输出的大量本地文件进行一次合并。Combiner函数执行时机可能是在map的merge操作完成之前</p><h3 id="MapReduce各种输入输出"><a href="#MapReduce各种输入输出" class="headerlink" title="MapReduce各种输入输出"></a>MapReduce各种输入输出</h3><p><strong>InputFormat</strong>：负责处理MR的输入部分，来决定Map的数量，InputFormat</p><p><strong>FileInputFormat</strong>：是所有以文件作为数据源的InputFormat实现的基类，FileInputFormat保存作为job输入的所有文件</p><h2 id="MapReduce-设计模式"><a href="#MapReduce-设计模式" class="headerlink" title="MapReduce 设计模式"></a>MapReduce 设计模式</h2><ul><li><p><strong>过滤器模式</strong>：设定某种条件，当负责条件时保留数据，不符合条件时丢弃数据</p></li><li><p><strong>Top N</strong>：根据数据集的排名，获取前N条记录</p></li><li><p><strong>去重模式</strong>：去重</p></li><li><p><strong>数据重组</strong>：按照一定的规划整理数据。数据重组要求划分的分区数量已经确定，划分分区的条件已经确定</p></li><li></li></ul></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="categories/课程笔记/" class="category-chain-item">课程笔记</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="tags/Java/">#Java</a> <a href="tags/hadoop/">#hadoop</a></div></div><div class="license-box my-3"><div class="license-title"><div>Hadoop 知识整理</div><div>2023/06/04/subject/hadoop/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>charlesix59</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2023年6月4日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/2023/06/04/fantasy/02/" title="窗边"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">窗边</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="2023/05/31/fantasy/01/" title="一夜"><span class="hidden-mobile">一夜</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article id="comments" lazyload><div id="waline"></div><script type="text/javascript">Fluid.utils.loadComments("#waline",(function(){Fluid.utils.createCssLink("https://lib.baomitu.com/waline/2.5.1/waline.min.css"),Fluid.utils.createScript("https://lib.baomitu.com/waline/2.5.1/waline.min.js",(function(){var i=Object.assign({serverURL:"https://hexo-comment-qncm4vegj-charlesix59.vercel.app/",path:"window.location.pathname",meta:["nick","mail","link"],requiredMeta:["nick"],lang:"zh-CN",emoji:["https://cdn.jsdelivr.net/gh/walinejs/emojis/bilibili"],dark:'html[data-user-color-scheme="dark"]',wordLimit:0,pageSize:10},{el:"#waline",path:window.location.pathname});Waline.init(i),Fluid.utils.waitElementVisible("#waline .vcontent",()=>{var i="#waline .vcontent img:not(.vemoji)";Fluid.plugins.imageCaption(i),Fluid.plugins.fancyBox(i)})}))}))</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><script>Fluid.utils.createScript("https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js",(function(){mermaid.initialize({theme:"default"})}))</script><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class=":" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content">create by Charles Min at 2022 @CopyRight</div><div class="statistics"><span id="busuanzi_container_site_pv" style="display:none">总访问量 <span id="busuanzi_value_site_pv"></span> 次 </span><span id="busuanzi_container_site_uv" style="display:none">总访客数 <span id="busuanzi_value_site_uv"></span> 人</span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var o=jQuery("#board-ctn").offset().top;window.tocbot.init({tocSelector:"#toc-body",contentSelector:".markdown-body",headingSelector:CONFIG.toc.headingSelector||"h1,h2,h3,h4,h5,h6",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",collapseDepth:CONFIG.toc.collapseDepth||0,scrollSmooth:!0,headingsOffset:-o}),t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var o=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),n=[];for(var i of o)n.push(".markdown-body > "+i.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(n.join(", "))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script src="/js/local-search.js"></script><script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript><script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script><script data-pjax>function GithubCalendarConfig(){var t=document.getElementById("recent-posts");t&&"/about/"==location.pathname&&(console.log("已挂载github calendar"),t.insertAdjacentHTML("afterbegin",'<div id="github-calendar" style="width:100%;height:auto;padding:10px;margin-bottom:20px"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>')),GithubCalendar("https://python-github-calendar-api.vercel.app/api?charlesix59",["#ebedf0","#fdcdec","#fc9bd9","#fa6ac5","#f838b2","#f5089f","#c4067e","#92055e","#540336","#48022f","#30021f"],"charlesix59")}document.getElementById("recent-posts")&&GithubCalendarConfig()</script><style>#github_container{min-height:280px}@media screen and (max-width:650px){#github_container{min-height:0}}</style><style>#github_container>.position-relative>.border{border:0!important}#github-calendar{position:relative;margin-top:-2rem;background-color:var(--board-bg-color);transition:background-color .2s ease-in-out;border-radius:.5rem;z-index:3;-webkit-box-shadow:0 12px 15px 0 rgb(0 0 0 / 24%),0 17px 50px 0 rgb(0 0 0 / 19%);box-shadow:0 12px 15px 0 rgb(0 0 0 / 24%),0 17px 50px 0 rgb(0 0 0 / 19%)}</style></body></html>